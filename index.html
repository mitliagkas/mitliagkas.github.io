---
layout: default
---


<div class="home">

<!--   <table style="text-align: left; width: 90%;" border="0" cellpadding="2" cellspacing="2"> --> 

<table style="text-align: left;" border="0">
    <tbody>
      <tr>
        <td style="width=20%;vertical-align: top;">
        <img title="Γιάννης Μητλιάγκας", style="width:100%;" alt="Γιάννης Μητλιάγκας" src="ioannis-headshot-scaled.jpg">
	Γιάννης Μητλιάγκας
	<br>
	<br>
	<a href="https://diro.umontreal.ca/repertoire-departement/professeurs/professeur/in/in29391/sg/Ioannis%20Mitliagkas/" target="_blank">
        <img title="UdeM", style="width:80%;" alt="UdeM" src="images/logo-udem.png">
	<br>
	Associate professor,
	Computer Science,
	University of Montr&eacute;al
	</a>
	<br>
	<br>
	<a href="https://mila.quebec/en/person/ioannis-mitliagkas/" target="_blank">
        <img title="Mila", style="width:60%;" alt="Mila" src="images/logo-mila.png">
	<br>
	Core faculty at Mila
	<br>
	<br>
	</a>
	<a href="https://deepmind.google/" target="_blank">
        <img title="Google DeepMind", style="width:100%;" alt="Google DeepMind" src="images/logo-google.png">
	<br>
	Staff research scientist
	<br>
	Google DeepMind
	</a>
	<br>
	<br>
	<a href="https://archimedesai.gr/en/researchers" target="_blank">
        <img title="Archimedes", style="width:80%;" alt="Archimedes" src="images/logo-archimedes.svg">
	<br>
	Affiliated Researcher
	<br>
	Archimedes, Athens
	</a>
	<br>
	<br>
	<a href="https://www.cifar.ca/ai/pan-canadian-artificial-intelligence-strategy/the-canada-cifar-ai-chairs" target="_blank">
        <img title="CIFAR", style="width:50%;" alt="CIFAR" src="images/logo-cifar.jpg">
	<br>
	Canada CIFAR AI Chair 
	</a>
	<br>
	<br>
	<a href="https://mtl-mlopt.github.io" target="_blank">
        <img title="MTL MLOpt", style="width:70%;" alt="MTL MLOpt" src="images/logo-mtl-mlopt.png">
	<br>
	Founder, organizer
	</a>
	<br>
	<br>
	<br>
	<br>
	<br>

	<center>
	</center>
		<a href="cv.pdf" target="_blank">CV (September 2024)</a>
	<br>
	<br>


	<a href="mailto:ioannis@iro.umontreal.ca" target="_blank">Email,</a>
	<a href="https://scholar.google.com/citations?user=K757SxgAAAAJ&hl=en&oi=ao" target="_blank">Scholar,</a>
	<a href="https://twitter.com/bouzoukipunks" target="_blank">Twitter,</a>
	<a href="https://www.linkedin.com/in/ioannis-mitliagkas-6a8241131/" target="_blank">LinkedIn</a>


	</td>
        <td width=30px></td>
        <td style="vertical-align: top;">
	Researcher in machine learning.
	Academic, immigrant, amateur musician, runner.
	<br>
	<br>
 I research topics in optimization, dynamics and learning, 
	with a focus on modern machine learning. 
	I have done work in the intersection of systems and theory.
	<!--I am interested in systems for modern machine learning and data analysis.-->
	Some recent topics:
	<ul>
		<li>Min-max optimization and the dynamics of games</li>
		<li>Generalization and domain adaptation</li>
		<li>Optimization for deep learning</li> 
		<li>Statistical learning and inference</li>
	</ul>
	See the incomplete (and slightly outdated) summary of
	<a href="research-contributions.pdf" target="_blank">research contributions</a>
 	from my group.
	For a list of representative projects grouped by topic (last updated in early 2022), please consult the <a href="/projects">projects page</a>.
	Or check out 
	<a href="https://scholar.google.com/citations?hl=en&user=K757SxgAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">recent manuscript activity</a>
		for an idea of what I'm doing now.

    <br>
    <br>

    I work as an associate professor at the University of Montreal, and core faculty member at Mila.
    Grateful recipient of the Canada CIFAR AI Chair.
    My most important responsibility is the supervision of a dozen very talented junior researchers.
	Every fall, I teach <a href="/ift6390-ml-class">ML</a> to 100-200 grad students.
	Every winter, I teach an advanced research class on <a href="/ift6085-dl-theory-class">deep learning theory</a>.


	<br>
	<br>

	<font color="red" style="font-weight:bold">
		Prospective students: 
	</font>
	I will be looking for particularly strong students, for MSc or PhD for the fall of 2025.
	Unfortunatley, I might not be able to respond to all emails.
	Please make sure to go over my  
	<a href="https://scholar.google.com/citations?hl=en&user=K757SxgAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">recent publications</a>
	and list of recent projects (below). 
	If you think that we have a strong overlap in interests 
<!--  already done research in the area feel free to email me.	a strong background in mathematics and computation, -->
	please make sure to submit
	your <a href="https://mila.quebec/en/prospective-students-and-postdocs/research-programs/request-supervisor" target="_blank">supervision request</a> 
	 by December 1st (form opens in mid-October) and mention me as one of your faculty of choice.
I will consider all good candidates, but pay extra attention to those from unusual backgrounds, underrepresented groups, and candidates coming from regions under threat of war, occupation, political instability, etc (Ukraine, Palestine, Africa, … ). 
    <br>
    <br>

    For the winter semester of 2025, I am on sabbatical at
    <a href="https://archimedesai.gr/en/researchers">Archimedes</a> in Athens, Greece.
    <br>
    <br> 

    In Montreal, I work part-time as a research scientist at Google DeepMind. 
    <br>
    <br> 
    I co-founded and hosted the first 2 seasons of <a href="https://mtl-mlopt.github.io/">MTL MLOpt</a>,
    a bi-weekly meeting of optimization experts from Mila, UdeM, McGill (CS and math), Google DeepMind,
    SAIL, FAIR, MSR. 
    We proudly share our <a href="https://youtube.com/playlist?list=PLqrJF7iQbscALPio49SSil8XDbfNAlOTO">guest speaker videos</a>.
    <br>
    <br>

    In in the early days of interest in the area, I co-organized the 
    <a href="https://sgo-workshop.github.io/">Smooth games optimization and ML</a> 
    workshop series at NeurIPS.
    The <a href="https://slideslive.com/38924034/opening-remarks?ref=speaker-22001-latest ">opening remarks</a> video from NeurIPS 2019, gives a nice summary of our motivation for this line of work. 
    For a summary of relevant work in my lab you can check out this 
    <a href="https://docs.google.com/presentation/d/1uYUt7zSUByOGt_yAecSTBj_V0jNNGEySRU2hkXNyvKA/edit?usp=sharing">slide deck</a>. 
    In spring 2022 I was invited to participate at the 
    <a href="https://simons.berkeley.edu/programs/games2022">semester on Learning and Games</a> at Simons Institute at Berkeley, CA.
    <br>
    <br>



	For the last few summers I was honored to be invited to teach optimization for ML at the
	<a href="https://deeplearning.neuromatch.io/tutorials/W1D5_Optimization/student/W1D5_Tutorial1.html">
		Neuromatch Academy's deep learning course</a>.


	<br>
	<br>


	Before joining the University of Montreal, I was a postdoc with the Departments of Computer Science and Statistics at Stanford University and a PhD candidate at The University of Texas at Austin.
<!--
        working with <a href="http://cs.stanford.edu/people/chrismre/" target="_blank">Chris R&eacute;</a> and <a href="http://web.stanford.edu/~lmackey/" target="_blank">Lester Mackey</a>.
	I got my PhD at The University of Texas at Austin with <a href="http://users.ece.utexas.edu/%7Ecmcaram/" target="_blank">Constantine Caramanis</a> and <a href="http://www.ece.utexas.edu/people/faculty/sriram-vishwanath" target="_blank">Sriram Vishwanath</a>,
	 where I also worked with <a href="http://users.ece.utexas.edu/~dimakis/" target="_blank">Alex Dimakis</a>.
-->

	</td>
        <!-- <img style="width: 200px; height: 300px;" alt="That's me." src="colourPortrait.jpg"></td>
         --><td style="vertical-align: top;">&nbsp;&nbsp; <br>
        </td>
      </tr>
    </tbody>
  </table>



<!--h2>Recent projects</h2>

A (slightly outdated) curated list of some of my most exciting research projects.
For a thorough list of projects grouped by topic, please consult the 
<a href="/projects">projects page</a>.
Publications listed below, in the present page.

<br>
<br>

<div id ="imagelist">
<ul>

      <li>
      <a href="https://arxiv.org/abs/2106.06607" target="_blank">
      <img src="{{ site.baseurl }}/images/project-irb.png" alt="" title="Invariance Principle Meets Information Bottleneck for Out-of-Distribution Generalization ">
      <div>
	Invariance Principle Meets Information Bottleneck for Out-of-Distribution Generalization
        <em>
	We prove that using the "information bottleneck" along with invariance helps address key failures of IRM.
	We propose an approach that incorporates both of these principles and demonstrate its effectiveness. 
	</em>
	<br>
	Lead: Kartik Ahuja
      </div></a>
      </li> 
      <li>
      <a href="https://arxiv.org/abs/2009.05475"  target="_blank">
      <img src="{{ site.baseurl }}/images/project-dsm-als.png" alt="" title="Adversarial score matching and improved sampling for image generation">
      <div>
	Adversarial score matching and sampling for image generation
        <em>
	We dig into recently proposed deep generative methods based on denoising score mathing and annealed Langevin Sampling (DSM-ALS). We identify two weaknesses in existing methodology and address them to provide state-of-the-art generative performance. 
	</em>
	<br>
	Lead: Alexia Jolicoeur-Martineau
      </div></a>
      </li> 
      <li>
      <a href="https://arxiv.org/abs/2010.11924" target="_blank">
      <img src="{{ site.baseurl }}/images/project-robust-measures.png" alt="" title="In Search of Robust Measures of Generalization">
      <div>
	In Search of Robust Measures of Generalization
        <em>
	We look into the experimental evaluation of generalization measures for neural networks.
	We argue that generalization measures should be evaluated within the framework of distributional robustness 
	and provide methodology and experimental results on a variety of architectures.
	</em>
	<br>
	Lead: Karolina Dziugaite, Alexandre Drouin (ServiceNow/ElementAI)
      </div></a>
      </li> 
	
      <li>
      <a href="https://arxiv.org/abs/2110.10815"  target="_blank">
      <img src="{{ site.baseurl }}/images/project-feedback-alignment.png" alt="" title="Convergence Analysis and Implicit Regularization of Feedback Alignment for Deep Linear Networks">
      <div>
	Implicit Regularization with Feedback Alignment 
        <em>
We analyze feedback alignment and study incremental learning phenomena for linear networks. Interestingly, certain initializations imply that negligible components are learned before the principal ones; a phenomenon we classify as implicit anti-regularization.
    </em>
    <br>
    Lead: Manuela Girotti
      </div></a>
      </li> 
      <li>
      <a href="http://proceedings.mlr.press/v130/guille-escuret21a.html"  target="_blank">
      <img src="{{ site.baseurl }}/images/project-condition-numbers.png" alt="" title="A Study of Condition Numbers for First-Order Optimization ">
      <div>
	A Study of Condition Numbers for First-Order Optimization
        <em>
		Condition numbers are not continuous!! (seriously it wreaks havoc with tuning)
		We perform a comprehensive study of alternative metrics which we prove to be continuous.
		Finally we discuss how our work impacts the theoretical understanding of FOA and their performances.
    </em>
    <br>
    Lead: Charles Guille-Escuret, Baptiste Goujaud
      </div></a>
      </li> 
      <li>
      <a href="https://www.bradyneal.com/bias-variance-tradeoff-textbooks-update" target="_blank">
      <img src="{{ site.baseurl }}/images/project-bias-variance.png" alt="Bias-variance tradeoff" title="A Modern Take on the Bias-Variance Tradeoff in Neural Networks">
      <div>
        A Modern Take on the Bias-Variance Tradeoff in Neural Networks
        <em>
	We measure prediction bias and variance in NNs.
	Both bias and variance decrease as the number of parameters
	grows. We decompose variance into
	variance due to sampling and variance due to initialization.
	</em>
	<br>
	Lead: Brady Neal
      </div></a>
      </li> 
      <li>
      <a href="https://arxiv.org/abs/2001.00602"  target="_blank">
      <img src="{{ site.baseurl }}/images/project-games-spectral-shapes.png" alt="" title="Accelerating Smooth Games by Manipulating Spectral Shapes ">
      <div>
	Accelerating Smooth Games by Manipulating Spectral Shapes
        <em>
	We use matrix iteration theory to characterize acceleration in smooth games.
	The spectral shape of a family of games is the set containing all eigenvalues of the Jacobians of standard gradient dynamics in the family.
	</em>
	<br>
	Lead: Waiss Azizian
      </div></a>
      </li> 

      <li>
      <a href="https://arxiv.org/pdf/2001.00602.pdf"  target="_blank">
      <img src="{{ site.baseurl }}/images/project-negative-momentum.png" alt="" title="Negative Momentum for Improved Game Dynamics">
      <div>
        Negative Momentum for Improved Game Dynamics
        <em>
	Alternating updates are more stable than
	simultaneous updates on simple games.
	A negative momentum
	term achieves convergence in a difficult toy adversarial problem, but also on the notoriously
	difficult to train saturating GANs
	</em>
	<br>
	Lead: Gauthier Gidel, Reyhane Askari-Hemmat
      </div></a>
      </li> 
    </ul>
</div-->

  <br><br>

  <h2>Recent News</h2>
  <div id="" style="overflow-y:scroll; height:230px;">
  <ul>
		<li>June 2024: One more strong PhD graduation, this time it is Adam Ibrahim! He continues his work as a research scientist at H, Paris. Congratulations Dr. Ibrahim!
		<li>May 2024: <a href="https://arxiv.org/abs/2306.11922">No Wrong Turns: The Simple Geometry Of Neural Networks Optimization Paths</a> paper accepted at ICML 2024!
		<li>May 2024: For the first time in a long while, I'm attending a big ML conference. I will be at ICLR 2024 in Vienna. 
		<li>April 2024: My second PhD student to graduate, Reyhane Askari Hemmat, has successfully defended her thesis. She continues her work as a research scientist at Meta, Montreal. Congratulations Dr. Askari!
		<li>January 2024: <a href="https://iclr.cc/virtual/2024/poster/17398">Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation</a> paper accepted at ICLR 2024 for an 
		       	<span style="font-weight:bold">
			<font color="red">
				spotlight presentation.
			</font>
			</span> 
		<li>January 2024: <a href="https://openreview.net/pdf?id=vXSsTYs6ZB">LEAD: Min-Max Optimization from a Physical Perspective</a> invited to be presented at ICLR 2024 
		<li>December 2023: For the winter semester of 2024, I am on sabbatical at <a href="https://archimedesai.gr/en/researchers">Archimedes</a> in Athens, Greece.
		<li>September 2023: <a href="https://nips.cc/virtual/2023/oral/73849">Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation</a> paper accepted at NeurIPS 2023 for an 
		       	<span style="font-weight:bold">
			<font color="red">
				oral presentation	
			</font>
			</span> 
		<li>September 2023: <a href="https://nips.cc/virtual/2023/poster/71706">CADet: Fully Self-Supervised Out-Of-Distribution Detection With Contrastive Learning</a> paper accepted at NeurIPS 2023 
		<li>September 2023: Welcome to new PhD student, <a href="https://openreview.net/profile?id=~Zichu_Liu1">Zichu Liu</a>.
		<li>September 2023: Welcome to new intern,  <a href="https://github.com/AngeClementAkazan">Ange-Clement Akazan</a> who's visitting us from the African Institute for Mathematical Research and will study generative models
		<li>April 2023: <a href="https://openreview.net/forum?id=SykskBAkZL">Synergies between Disentanglement and Sparsity: Generalization and Identifiability in Multi-Task Learning</a> paper accepted at ICML 2023.
		<li>January 2023: My first PhD student to graduate, Alexia Jolicoeur-Martineau, has successfully defended her thesis. She continues her work as a research scientist at SAIL Montreal. Congratulations Dr. Jolicoeur-Martineau!!
		<li>January 2023: <a href="https://arxiv.org/abs/2304.06879">Performative Prediction with Neural Networks
</a> paper accepted at AISTASTS 2023.
		<li>January 2023: <a href="https://iclr.cc/virtual/2023/poster/11421">Neural Networks Efficiently Learn Low-Dimensional Representations with SGD</a> paper accepted at ICLR 2023 with honorable mention.
	  	<li>September 2022: I'm excited to announce that I've started part-time work as a staff research scientist at Google Brain Montreal! Looking forward to deepening my connection to larger scale problems in industry.
		<li>September 2022: <a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/9daab3b451038ed1bc5d8e9b77996b99-Abstract-Conference.html">Gradient Descent Is Optimal Under Lower Restricted Secant Inequality And Upper Error Bound</a> paper accepted at NeurIPS 2022.
	  	<li>September 2022: Kartik Ahuja has finished his postdoc and started working as a research scientist at Meta research (FAIR) Paris! 
	  	<li> July 2022: Graduating PhD candidate Alexia Jolicoeur-Martineau started work at Samsung SAIT AI Lab in Montreal! 
	  	<li> June 2022: As of June 1st, 2022 I was promoted to the post of associate professor with tenure. My sincere thanks to colleagues and my group for all their hard work.
	  	<li>October 2021: Honored to be invited to the semester of <a href="https://simons.berkeley.edu/programs/games2022">Learning and Games</a> at Simons. I will be visitting Berkeley in January-March of 2022.
		<li>September 2021: 
			Welcome to new MSc students, 
			<a href="https://github.com/mhrnz"> Mehrnaz Mofakhami</a> and 
			<a href="https://divyat09.github.io/">Divyat Mahajan</a>.
		<li>September 2021: Two papers accepted at NeurIPS 2021!
			[<a href="https://arxiv.org/abs/2107.00052">one</a>, 
			<a href="https://arxiv.org/abs/2106.06607">two</a>]
		<li>April 2021: Postdoc in our group, Nicolas Loizou accepted a tenure track position at Johns Hopkins University!
		<li>March 2021: Postdoc in our group, Manuela Girotti accepted a tenure track position at St. Mary's University! In the meantime shewill spend time at the prestigious mathematical institute, MSRI, in Berkeley, CA.  
		<li>January 2021: Best student paper award for Charles, Baptiste and Manuela's paper at OPT2020! For their work on the <a href="https://arxiv.org/abs/2012.05782">fundamentals of condition numbers</a>. Their paper was accepted for publication at AISTATS 2021. 
		<li>January 2021: Alexia and Rémi's paper, in collaboration with MSR Montréal has been accepted at ICLR 2021! Preprint available <a href="https://arxiv.org/abs/2009.05475">here</a>.
		<li>September 2020: Paper on 
			<a href="https://arxiv.org/abs/2010.11924">evaluating generalization measures</a>
			accepted at NeurIPS'20.
		<li>September 2020: 
			Welcome to new PhD students, 
			<a href="https://ca.linkedin.com/in/ryan-d-orazio-05833979">Ryan D'Orazio</a> and 
			<a href="https://hiroki11x.github.io">Hiroki Naganuma</a>.
		<li>August 2020: Kartik Ahuja awarded the IVADO postdoctoral scholarship. Excited to have him join us in January 2021!
		<li>April 2020: Two papers on differentiable games 
			(<a href="https://arxiv.org/abs/2007.04202">one</a>, 
			<a href="https://arxiv.org/abs/1906.07300">two</a>)
			accepted at ICML'20.
		<li>January 2020: Two papers on efficient methods and tight bounds for differentiable games 
			(<a href="https://arxiv.org/pdf/2001.00602.pdf">one</a>, 
			<a href="https://arxiv.org/pdf/1906.05945.pdf">two</a>)
			accepted at AISTATS'20.
		<li>December 2019: Nicolas Loizou was awarded the IVADO postdoctoral scholarship at the prestigious Fellow tier.
		<li>December 2019: Brady Neal graduates with an MSc. He will continue on his PhD with us.
		<li>November 2019: Excited to be coorganizing the 2nd iteration of the <a href="https://sgo-workshop.github.io/">Smooth Games Optimization and Machine Learning Workshop</a> at NeurIPS'19.
		<li>November 2019: <a href="https://arxiv.org/abs/1906.03532">Reducing the variance in online optimization by transporting past gradients</a> selected for
		       	<span style="font-weight:bold">
			<font color="red">
				spotlight oral presentation	
			</font>
			</span> 
			at NeurIPS'19.
		<li>October 2019: Multiple submissions to AISTATS. Preprints on the way...
		<li>June 2019: At ICML with 3 papers in main conference, 2 in Deep Learning Phenomena workshop.
		<li>May 2019: <a href="https://arxiv.org/pdf/1905.11382.pdf">State-Reification Networks</a> selected for
		       	<span style="font-weight:bold">
			<font color="red">
				oral presentation	
			</font>
			</span> 
			at ICML'19.
		<li>April 2019: Excited to be <a href="https://i.redd.it/kovwct2jeix21.png">listed</a> among the most prolific authors of accepted ICML 2019 papers.
		<li>April 2019: I received the NSERC Discovery grant!
		<li>April 2019: In Japan for AISTATS.
		<li>January 2019: h-detach paper accepted at ICLR.
		<li>December 2018: Was nominated in the first cohort of Canada CIFAR AI chairs!!
		<li>December 2018: Co-organizing <a href="https://sgo-workshop.github.io/">Smooth Games Optimization in ML</a> workshop at NeurIPS.
		<li>December 2018: Negative momentum for improved game dynamics. Paper accepted at AISTATS 2019.
		<li>December 2018: Full version of YellowFin manscript accepted at SysML
		<li>September 2018: Excited to be teaching Machine Learning to a class of 180 graduate students at UdeM.
		<li>February 2018: <a href="https://arxiv.org/pdf/1706.03471.pdf">YellowFin</a> selected for
		       	<span style="font-weight:bold">
			<font color="red">
				oral presentation	
			</font>
			</span> 
			at SysML'18.
		<li>January 2018: Teaching new class! 
	      <a href="ift6085-dl-theory-class/">
		IFT 6085: Theoretical principles for deep learning
		</a>
		<li>December 2017: Accelerated power iteration via momentum, paper accepted at AISTATS 2018.
		<li>November 2017: Talk at Google Brain, Montréal
			<li>September 2017: Thrilled to be starting work at the University of Montreal and the Mila as an assistant professor!
		<li>August 2017: Visiting my alma mater, UT Austin.
		<li>August 2017: At Sydney for ICML, presenting work on YellowFin, custom scans for Gibbs sampling, and deep learning for 3D point cloud representation and generation.
		<li>July 2017: 
			<span style="font-weight:bold">
			<font color="red">
				New preprint!
			</font>
			</span> Representation Learning and Adversarial Generation of 3D Point Clouds
				<a href="https://arxiv.org/abs/1707.02392">[arxiv]</a>.
		<li>July 2017: 
			<span style="font-weight:bold">
			<font color="red">
				New preprint!
			</font>
			</span> Accelerated stochastic power iteration
				<a href="https://arxiv.org/abs/1707.02670">[arxiv]</a>.
		<li>June 2017: 
			<span style="font-weight:bold">
			<font color="red">
				New preprint!
			</font>
			</span> An automatic tuner for they hyperparameters of momentum SGD 
				<a href="https://arxiv.org/pdf/1706.03471.pdf">[arxiv]</a>.
		<li>May 2017: Custom scan sequence paper accepted for presentation at ICML 2017!
		<li>April 2017: Invited talk at Workshop on Advances in Computing Architectures, Stanford SystemX
		<li>March 2017: 
		<span style="font-weight:bold">
		<font color="red">
			New preprint!
		</font>
		</span> Custom scan sequences for 
			<a href="https://arxiv.org/pdf/1707.05807.pdf">super fast Gibbs sampling</a>.
		<li>February 2017: Invited to talk at ITA in San Diego.
		<li>February 2017: Spoke at the AAAI 2017 Workshop on Distributed Machine Learning.
		<li>January 2017: Visiting Microsoft Research, Cambridge
		<li>December 2016: At NIPS, presenting our
			<a href="https://arxiv.org/abs/1606.03432">Gibbs sampling paper</a>
		  	dispelling some common beliefs regarding scan orders.
		<li>November 2016: Visiting Microsoft Research New England
		<li>November 2016: Invited talk at SystemX Stanford Alliance Fall Conference 
		<li>November 2016: Full version of asynchrony <a href="papers/asynchrony-begets-momentum.pdf">paper</a>.
	  	<li>September 2016: Talk at Allerton
	  	<li>August 2016: I had the pleasure to give a talk MIT Lincoln Labs.
	  	<li>August 2016: Gave an <a href="{{ site.baseurl}}/asynchrony/">asynchronous optimization</a> talk at Google.
		<li>August 2016: <a href="http://stanford.edu/~imit/tuneyourmomentum/">Blog post</a> on our momentum work.
	  	<li>July 2016: Invited to talk at NVIDIA.
		<li>June 2016: <a href="{{ site.baseurl}}/asynchrony/">Poster</a> at non-convex optimization ICML <a href="http://sites.google.com/site/noncvxicml16/">workshop</a>.
		<li>June 2016: <a href="https://arxiv.org/abs/1606.07365">Poster</a> at OptML 2016 workshop.
		<li>In a recent <a href="http://bit.ly/22wAt0e">note</a>,
		we show that asynchrony in SGD introduces momentum. 
		In the companion <a href="http://bit.ly/ovore">systems paper</a>, we use this
		theory to train deep networks faster.
		  <li>Does periodic model averaging always help? Recent <a href="https://arxiv.org/abs/1606.07365">results</a>.
		<li>Excited to start Postdoc at Stanford University. Will be working with Lester Mackey and Chris R&eacute;.</li>
		<li>Successfully defended my PhD thesis!</li>
		<li>SILO <a href="http://wid.wisc.edu/featured-events/silo032515/">seminar talk</a> at the Wisconsin Institute of Discovery. Loved both Madison and the WID!</li>
		<li>Densest k-Subgraph work <a href="http://devblogs.nvidia.com/parallelforall/gpu-accelerated-graph-analytics-python-numba/">picked up by NVIDIA</a>!</li>
		<li>Our latest <a href="papers/FrogWild.pdf">work</a> has been accepted for presentation at VLDB 2015!</li>
    </ul>
    </div>
    <br>

    <br>

  <h2>Students and postdocs</h2>



<table style="text-align: left;" border="0">
    <tbody>
      <tr>
        <td style="width=30%;vertical-align: top;">
	<a href="https://github.com/mhrnz" target="_blank">
        <img title="Mehrnaz Mofakhami", style="width:20%;" alt="Mehrnaz Mofakhami" src="images/person-mehrnaz.jpeg">
	Mehrnaz Mofakhami, MSc student
	</a>
	<br>
	<br>
	<a href="https://scholar.google.com/citations?user=VNgVRmgAAAAJ" target="_blank">
        <img title="Charles Guille-Escuret", style="width:20%;" alt="Charles Guille-Escuret" src="images/person-charles.jpg">
	Charles Guille-Escuret, PhD
	</a>
	<br>
	<br>
	<a href="https://ryan-dorazio.github.io" target="_blank">
        <img title="Ryan D'Orazio", style="width:20%;" alt="Ryan D'Orazio" src="images/person-ryan.jpg">
	Ryan D'Orazio, PhD
	</a>
	<br>
	<br>
	<a href="https://bradyneal.github.io/aboutme/" target="_blank">
        <img title="Brady Neal", style="width:20%;" alt="Brady Neal" src="images/person-brady.jpg">
	Brady Neal, PhD 
	</a>
	</td>
        <!--td width=30px></td-->
        <td style="width=50%;vertical-align: top;">
	<a href="https://openreview.net/profile?id=~Zichu_Liu1" target="_blank">
        <img title="Zichu Liu", style="width:20%;" alt="Zichu Liu" src="images/person-missing.png">
	Zichu Liu, PhD 
	</a>
	<br>
	<br>
	<a href="https://divyat09.github.io/" target="_blank">
        <img title="Divyat Mahajan", style="width:20%;" alt="Divyat Mahajan" src="images/person-divyat.jpg">
	Divyat Mahajan, PhD
	</a>
	<br>
	<br>
	<a href="https://hiroki11x.github.io" target="_blank">
        <img title="Hiroki Naganuma", style="width:20%;" alt="Hiroki Naganuma" src="images/person-hiroki.png">
	Hiroki Naganuma, PhD
	</a>
	<br>
	<br>
	<a href="https://www.adamibrahim.fr" target="_blank">
        <img title="Adam Ibrahim", style="width:20%;" alt="Adam Ibrahim" src="images/person-adam.jpg">
	Adam Ibrahim, PhD 
	</a>
	</td>
	<td style="vertical-align: top;">&nbsp;&nbsp; <br>
        </td>
      </tr>
    </tbody>
  </table>


    <br>



  <h2>Past students and supervisees
  (and their next steps) 
</h2>
<table style="text-align: left;" border="0">
    <tbody>
      <tr>
        <td style="width=50%;vertical-align: top;">
	<a href="https://nicolasloizou.github.io/" target="_blank">
	Nicolas Loizou, Postdoc (Assistant professor, Johns Hopkins University, 2022)
	</a>
	<br>
	<a href="https://mathemanu.github.io/" target="_blank">
	Manuela Girotti, Postdoc (Assistant professor, Emory University, Atlanta, GA, 2023)
	</a>
	<br>
	<a href="https://ahujak.github.io" target="_blank">
	Kartik Ahuja, Postdoc (Research Scientist at FAIR (Meta AI), 2022)
	</a>
	<br>
	<a href="https://ajolicoeur.ca/" target="_blank">
	Alexia Joilicoeur-Martineau, PhD (Research Scientist at Samsung SAIL Montreal, 2023)
	</a>
	<br>
	<a href="https://reyhaneaskari.github.io/" target="_blank">
	Reyhane Askari-Hemmat, PhD (Research Scientist at Meta)
	</a>
	<br>
	<a href="https://kilianfatras.github.io" target="_blank">
	Kilian Fatras, Postdoc (Research Scientist, DreamFold)
	</a><br>

	Brady Neal, MSc, Fall 2019 ( Senior Research Scientist at Dataiku, 2022)
	<br>
Remi Piche-Taillefer, MSc, Summer 2021 (MSR Montreal, 2021)
	<br>
	<a href="https://github.com/AngeClementAkazan" target="_blank">
	Ange-Clement Akazan, intern, Fall 2023 (MSc, AIMS)
	</a>
	<br>
	Baptiste Goujaud, intern, Summer 2019 (PhD candidate at Ecole Polytechnique Paris)
	<br>
	Seb Arnold, intern, Summer 2018 (PhD candidate at USC)
	<br>
	Amartya Mitra, intern, Spring-Summer 2020 (PhD candidate at UC Riverside)
	<br>
Nicolas Gagne, intern, Summer 2018 (PhD candidate at McGill)
	<br>
Vinayak Tantia, intern, 2018 (FAIR Montreal)
	</td>
        <td width=30px></td>
        <td style="width=50%;vertical-align: top;">
	</td>
	<td style="vertical-align: top;">&nbsp;&nbsp; <br>
        </td>
      </tr>
    </tbody>
  </table>

<br>

I also had the great opportunity to have very productive collaborations with the following researchers while they were students (though I did not supervise them).
<br>
<table style="text-align: left;" border="0">
    <tbody>
      <tr>
        <td style="width=50%;vertical-align: top;">
	Gauthier Gidel
	<br>
	Panos Achlioptas
	<br>
	Isabela Albuquerque
	<br>
	Joao Monteiro
	<br>
	Alex Lamb
	</td>
        <td width=30px></td>
        <td style="width=50%;vertical-align: top;">
	</td>
	<td style="vertical-align: top;">&nbsp;&nbsp; <br>
        </td>
      </tr>
    </tbody>
  </table>

  <br>
  <br>



<h2>Teaching</h2> 

<ul>
	<li>
	<font style="font-weight:bold">
		Fall 2025 [in person, french]</font>: <a href="/ift6390-ml-class/">
			IFT 3395/6390 - Fundamentals of Machine Learning 
		</a>
	<li>
	<font style="font-weight:bold">
		Fall 2024 [in french]</font>: <a href="/ift6390-ml-class/">
			IFT 3395/6390 - Fundamentals of Machine Learning 
		</a>
	<li>
		Fall 2023 [in person] <a href="/ift6390-ml-class/">
			IFT 6390 - Fundamentals of Machine Learning 
		</a>
	<li>
		Winter 2023 [hybrid]:
	 <a href="/ift6085-dl-theory-class/">
			IFT 6169 - Theoretical principles for deep learning
		</a>
	<li>
		Fall 2022 [hybrid]: <a href="/ift6390-ml-class/">
			IFT 6390 - Fundamentals of Machine Learning 
		</a>
	<li>
		Winter 2022 [hybrid]:
	 <a href="/ift6085-dl-theory-class/">
			IFT 6169 - Theoretical principles for deep learning
		</a>
	<li>
		Fall 2021 [hybrid]: <a href="/ift6390-ml-class/">
			IFT 6390 - Fundamentals of Machine Learning 
		</a>
	<li>
		Winter 2021:
	 <a href="/ift6085-dl-theory-class/">
			IFT 6085 - Theoretical principles for deep learning
		</a>
	<li>
		Fall 2020: <a href="/ift6390-ml-class/">
			IFT 6390 - Fundamentals of Machine Learning 
		</a>
	<li> Winter 2020:
	 <a href="/ift6085-dl-theory-class/">
			IFT 6085 - Theoretical principles for deep learning
		</a>
	<li>Fall 2019: <a href="/ift6390-ml-class/">
			IFT 6390 - Fundamentals of Machine Learning 
		</a>
	<li>Winter 2019: <a href="/ift6085-dl-theory-class/">
			IFT 6085 - Theoretical principles for deep learning
		</a>
	<li>Fall 2018: <a href="/ift6390-ml-class/">
			IFT 6390 - Fundamentals of Machine Learning 
		</a>
	<li>Winter 2018: <a href="/ift6085-dl-theory-class/">
			IFT 6085 - Theoretical principles for deep learning
		</a>
</ul>
			
    <br>

    <br>


  <h2>Publications</h2>
  <!-- {==% bibtex _plugins/style.bst biblio/biblio.bib %} -->

  This is a slightly outdated list of publications. For a more complete list of recent papers please visit my
<a href="https://scholar.google.com/citations?hl=en&user=K757SxgAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">scholar page</a>.
  <br>
  <br>

  {% include biblio-new.html %}

  {% include biblio.html %}

  <br>

  <h2>Older publications</h2>
  <!-- {==% bibtex _plugins/style.bst biblio/biblio.bib %} -->
  In another life, I did research in telecommunications as an electrical engineer.
  That experience was my gateway into information theory, optimization and statistics. 
  It also introduced me to the information theory community and some of their unique tools
  for dealing with statistical and learning problems.


  {% include biblio_older.html %}

  <br>

  <h2>Funding acknowledgements</h2>
        <img title="CIFAR", style="width:15%;" alt="CIFAR" src="images/logo-cifar.jpg">
        <img title="Apogee", style="width:20%;" alt="Apogee" src="images/logo-apogee.png">
        <img title="IVADO", style="width:20%;" alt="IVADO" src="images/logo-ivado.png">
        <img title="Samsung", style="width:20%;" alt="Samsung" src="images/logo-samsung.png">
	<br>
        <img title="Google DeepMind", style="width:18%;" alt="Google DeepMind" src="images/logo-google.png">
        <img title="FRQNT", style="width:18%;" alt="FRQNT" src="images/logo-frqnt.png">
        <img title="NSERC", style="width:18%;" alt="NSERC" src="images/logo-nserc.png">
        <img title="Microsoft Research", style="width:20%;" alt="Microsoft Research" src="images/logo-msr.png">
	<br>
	<br>
	Special thanks to Intel and NVIDIA for donating access to hardware
	and SigOPT for access to their platform for some of our work.
	

<!--   <h1 class="page-heading">Recent News</h1>

  <ul class="post-list">
    {% for post in site.posts %}
      <li>
        <span class="post-meta">{{ post.date | date: "%b %-d, %Y" }}</span>

        <h2>
          <a class="post-link" href="{{ post.url | prepend: site.baseurl }}">{{ post.title }}</a>
        </h2>
      </li>
    {% endfor %}
  </ul> -->

  <!--p class="rss-subscribe">subscribe <a href="{{ "/feed.xml" | prepend: site.baseurl }}">via RSS</a></p-->

</div>
